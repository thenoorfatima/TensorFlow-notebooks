{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FINAL-WAVE.ipynb","provenance":[{"file_id":"1XZcd_OPGyAcqd0efxkXVQrnrurDijyTK","timestamp":1575125953450}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3b3ec0eec9fd41ffa8ce56728a27087e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_907926931ca545dfa8a0c21574675829","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0db3b1e68df94c73a05152ed4e738f99","IPY_MODEL_975bc316ef2e4c7d97153e4cd77df620"]}},"907926931ca545dfa8a0c21574675829":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0db3b1e68df94c73a05152ed4e738f99":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_98fca5419dae4b2599414a8b58551a4c","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"danger","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a09511caf4f14e7da70d9c5fb37f8cb5"}},"975bc316ef2e4c7d97153e4cd77df620":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dd31fadd03714049b7b40b5ad87888d0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"  0% 0/50 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dedf9fb6d2e848edbdf19fe5032daa10"}},"98fca5419dae4b2599414a8b58551a4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a09511caf4f14e7da70d9c5fb37f8cb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dd31fadd03714049b7b40b5ad87888d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dedf9fb6d2e848edbdf19fe5032daa10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"1BmWxLUtf2Tu","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"d3c90cc3-1863-4247-b011-856c5237c65c","executionInfo":{"status":"ok","timestamp":1575353624368,"user_tz":-330,"elapsed":384519,"user":{"displayName":"Noor Fatima","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mApQYMABtajgCZCy7cF1as2H2UpI9g5drQw9DFD=s64","userId":"06775967229168824100"}}},"source":["#@title Download DIV2K Dataset\n","!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2019-12-03 06:07:20--  http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n","Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.162\n","Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip [following]\n","--2019-12-03 06:07:21--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n","Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.162|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3530603713 (3.3G) [application/zip]\n","Saving to: ‘DIV2K_train_HR.zip’\n","\n","DIV2K_train_HR.zip  100%[===================>]   3.29G  8.74MB/s    in 6m 18s  \n","\n","2019-12-03 06:13:40 (8.91 MB/s) - ‘DIV2K_train_HR.zip’ saved [3530603713/3530603713]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HwZTf2CuJtgY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":79},"outputId":"74a00e26-5f6a-475b-8968-7f522bb48145","executionInfo":{"status":"ok","timestamp":1575353626418,"user_tz":-330,"elapsed":386562,"user":{"displayName":"Noor Fatima","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mApQYMABtajgCZCy7cF1as2H2UpI9g5drQw9DFD=s64","userId":"06775967229168824100"}}},"source":["#@title Import Dependencies\n","import  os,shutil\n","import cv2\n","import numpy as np\n","from tqdm import tqdm_notebook as tqdm\n","import matplotlib.pyplot as plt\n","from keras.models import Input, Model\n","from keras.layers import BatchNormalization, LeakyReLU, Conv2D, Dense, \\\n","                         Flatten, Add, PReLU, Conv2DTranspose, Lambda, UpSampling2D                    \n","from keras.optimizers import Adam\n","from keras.applications import VGG19\n","from keras.callbacks import ReduceLROnPlateau\n","import tensorflow as tf"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O4OWkUzGw1BR","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e3fe6a23-3e4c-474a-feca-7f93cb7e87d9","executionInfo":{"status":"ok","timestamp":1575353664118,"user_tz":-330,"elapsed":424258,"user":{"displayName":"Noor Fatima","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mApQYMABtajgCZCy7cF1as2H2UpI9g5drQw9DFD=s64","userId":"06775967229168824100"}}},"source":["#@title Creating folder for the data and unziping the file\n","!mkdir train_data\n","shutil.move('./DIV2K_train_HR.zip','./train_data')\n","os.chdir('./train_data')\n","!unzip DIV2K_train_HR.zip\n","os.chdir('./DIV2K_train_HR')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Archive:  DIV2K_train_HR.zip\n","   creating: DIV2K_train_HR/\n","  inflating: DIV2K_train_HR/0103.png  \n","  inflating: DIV2K_train_HR/0413.png  \n","  inflating: DIV2K_train_HR/0031.png  \n","  inflating: DIV2K_train_HR/0660.png  \n","  inflating: DIV2K_train_HR/0126.png  \n","  inflating: DIV2K_train_HR/0793.png  \n","  inflating: DIV2K_train_HR/0764.png  \n","  inflating: DIV2K_train_HR/0550.png  \n","  inflating: DIV2K_train_HR/0437.png  \n","  inflating: DIV2K_train_HR/0374.png  \n","  inflating: DIV2K_train_HR/0755.png  \n","  inflating: DIV2K_train_HR/0614.png  \n","  inflating: DIV2K_train_HR/0646.png  \n","  inflating: DIV2K_train_HR/0371.png  \n","  inflating: DIV2K_train_HR/0312.png  \n","  inflating: DIV2K_train_HR/0108.png  \n","  inflating: DIV2K_train_HR/0556.png  \n","  inflating: DIV2K_train_HR/0794.png  \n","  inflating: DIV2K_train_HR/0722.png  \n","  inflating: DIV2K_train_HR/0780.png  \n","  inflating: DIV2K_train_HR/0555.png  \n","  inflating: DIV2K_train_HR/0439.png  \n","  inflating: DIV2K_train_HR/0396.png  \n","  inflating: DIV2K_train_HR/0666.png  \n","  inflating: DIV2K_train_HR/0254.png  \n","  inflating: DIV2K_train_HR/0344.png  \n","  inflating: DIV2K_train_HR/0062.png  \n","  inflating: DIV2K_train_HR/0657.png  \n","  inflating: DIV2K_train_HR/0117.png  \n","  inflating: DIV2K_train_HR/0395.png  \n","  inflating: DIV2K_train_HR/0015.png  \n","  inflating: DIV2K_train_HR/0335.png  \n","  inflating: DIV2K_train_HR/0578.png  \n","  inflating: DIV2K_train_HR/0142.png  \n","  inflating: DIV2K_train_HR/0719.png  \n","  inflating: DIV2K_train_HR/0101.png  \n","  inflating: DIV2K_train_HR/0579.png  \n","  inflating: DIV2K_train_HR/0504.png  \n","  inflating: DIV2K_train_HR/0576.png  \n","  inflating: DIV2K_train_HR/0590.png  \n","  inflating: DIV2K_train_HR/0158.png  \n","  inflating: DIV2K_train_HR/0384.png  \n","  inflating: DIV2K_train_HR/0795.png  \n","  inflating: DIV2K_train_HR/0668.png  \n","  inflating: DIV2K_train_HR/0144.png  \n","  inflating: DIV2K_train_HR/0642.png  \n","  inflating: DIV2K_train_HR/0427.png  \n","  inflating: DIV2K_train_HR/0593.png  \n","  inflating: DIV2K_train_HR/0080.png  \n","  inflating: DIV2K_train_HR/0050.png  \n","  inflating: DIV2K_train_HR/0617.png  \n","  inflating: DIV2K_train_HR/0608.png  \n","  inflating: DIV2K_train_HR/0118.png  \n","  inflating: DIV2K_train_HR/0082.png  \n","  inflating: DIV2K_train_HR/0788.png  \n","  inflating: DIV2K_train_HR/0042.png  \n","  inflating: DIV2K_train_HR/0333.png  \n","  inflating: DIV2K_train_HR/0346.png  \n","  inflating: DIV2K_train_HR/0705.png  \n","  inflating: DIV2K_train_HR/0195.png  \n","  inflating: DIV2K_train_HR/0671.png  \n","  inflating: DIV2K_train_HR/0213.png  \n","  inflating: DIV2K_train_HR/0692.png  \n","  inflating: DIV2K_train_HR/0253.png  \n","  inflating: DIV2K_train_HR/0191.png  \n","  inflating: DIV2K_train_HR/0628.png  \n","  inflating: DIV2K_train_HR/0354.png  \n","  inflating: DIV2K_train_HR/0003.png  \n","  inflating: DIV2K_train_HR/0393.png  \n","  inflating: DIV2K_train_HR/0336.png  \n","  inflating: DIV2K_train_HR/0674.png  \n","  inflating: DIV2K_train_HR/0586.png  \n","  inflating: DIV2K_train_HR/0074.png  \n","  inflating: DIV2K_train_HR/0116.png  \n","  inflating: DIV2K_train_HR/0270.png  \n","  inflating: DIV2K_train_HR/0376.png  \n","  inflating: DIV2K_train_HR/0650.png  \n","  inflating: DIV2K_train_HR/0462.png  \n","  inflating: DIV2K_train_HR/0046.png  \n","  inflating: DIV2K_train_HR/0545.png  \n","  inflating: DIV2K_train_HR/0347.png  \n","  inflating: DIV2K_train_HR/0187.png  \n","  inflating: DIV2K_train_HR/0713.png  \n","  inflating: DIV2K_train_HR/0558.png  \n","  inflating: DIV2K_train_HR/0319.png  \n","  inflating: DIV2K_train_HR/0073.png  \n","  inflating: DIV2K_train_HR/0033.png  \n","  inflating: DIV2K_train_HR/0207.png  \n","  inflating: DIV2K_train_HR/0290.png  \n","  inflating: DIV2K_train_HR/0194.png  \n","  inflating: DIV2K_train_HR/0246.png  \n","  inflating: DIV2K_train_HR/0034.png  \n","  inflating: DIV2K_train_HR/0621.png  \n","  inflating: DIV2K_train_HR/0768.png  \n","  inflating: DIV2K_train_HR/0366.png  \n","  inflating: DIV2K_train_HR/0490.png  \n","  inflating: DIV2K_train_HR/0471.png  \n","  inflating: DIV2K_train_HR/0475.png  \n","  inflating: DIV2K_train_HR/0152.png  \n","  inflating: DIV2K_train_HR/0636.png  \n","  inflating: DIV2K_train_HR/0338.png  \n","  inflating: DIV2K_train_HR/0358.png  \n","  inflating: DIV2K_train_HR/0523.png  \n","  inflating: DIV2K_train_HR/0456.png  \n","  inflating: DIV2K_train_HR/0470.png  \n","  inflating: DIV2K_train_HR/0522.png  \n","  inflating: DIV2K_train_HR/0426.png  \n","  inflating: DIV2K_train_HR/0587.png  \n","  inflating: DIV2K_train_HR/0465.png  \n","  inflating: DIV2K_train_HR/0236.png  \n","  inflating: DIV2K_train_HR/0192.png  \n","  inflating: DIV2K_train_HR/0458.png  \n","  inflating: DIV2K_train_HR/0438.png  \n","  inflating: DIV2K_train_HR/0176.png  \n","  inflating: DIV2K_train_HR/0016.png  \n","  inflating: DIV2K_train_HR/0392.png  \n","  inflating: DIV2K_train_HR/0054.png  \n","  inflating: DIV2K_train_HR/0063.png  \n","  inflating: DIV2K_train_HR/0537.png  \n","  inflating: DIV2K_train_HR/0271.png  \n","  inflating: DIV2K_train_HR/0409.png  \n","  inflating: DIV2K_train_HR/0328.png  \n","  inflating: DIV2K_train_HR/0582.png  \n","  inflating: DIV2K_train_HR/0532.png  \n","  inflating: DIV2K_train_HR/0706.png  \n","  inflating: DIV2K_train_HR/0153.png  \n","  inflating: DIV2K_train_HR/0401.png  \n","  inflating: DIV2K_train_HR/0110.png  \n","  inflating: DIV2K_train_HR/0316.png  \n","  inflating: DIV2K_train_HR/0069.png  \n","  inflating: DIV2K_train_HR/0209.png  \n","  inflating: DIV2K_train_HR/0351.png  \n","  inflating: DIV2K_train_HR/0433.png  \n","  inflating: DIV2K_train_HR/0534.png  \n","  inflating: DIV2K_train_HR/0525.png  \n","  inflating: DIV2K_train_HR/0353.png  \n","  inflating: DIV2K_train_HR/0018.png  \n","  inflating: DIV2K_train_HR/0592.png  \n","  inflating: DIV2K_train_HR/0041.png  \n","  inflating: DIV2K_train_HR/0398.png  \n","  inflating: DIV2K_train_HR/0355.png  \n","  inflating: DIV2K_train_HR/0492.png  \n","  inflating: DIV2K_train_HR/0258.png  \n","  inflating: DIV2K_train_HR/0051.png  \n","  inflating: DIV2K_train_HR/0339.png  \n","  inflating: DIV2K_train_HR/0156.png  \n","  inflating: DIV2K_train_HR/0174.png  \n","  inflating: DIV2K_train_HR/0526.png  \n","  inflating: DIV2K_train_HR/0168.png  \n","  inflating: DIV2K_train_HR/0515.png  \n","  inflating: DIV2K_train_HR/0289.png  \n","  inflating: DIV2K_train_HR/0700.png  \n","  inflating: DIV2K_train_HR/0711.png  \n","  inflating: DIV2K_train_HR/0317.png  \n","  inflating: DIV2K_train_HR/0310.png  \n","  inflating: DIV2K_train_HR/0075.png  \n","  inflating: DIV2K_train_HR/0533.png  \n","  inflating: DIV2K_train_HR/0345.png  \n","  inflating: DIV2K_train_HR/0238.png  \n","  inflating: DIV2K_train_HR/0493.png  \n","  inflating: DIV2K_train_HR/0019.png  \n","  inflating: DIV2K_train_HR/0559.png  \n","  inflating: DIV2K_train_HR/0268.png  \n","  inflating: DIV2K_train_HR/0746.png  \n","  inflating: DIV2K_train_HR/0648.png  \n","  inflating: DIV2K_train_HR/0112.png  \n","  inflating: DIV2K_train_HR/0639.png  \n","  inflating: DIV2K_train_HR/0216.png  \n","  inflating: DIV2K_train_HR/0170.png  \n","  inflating: DIV2K_train_HR/0408.png  \n","  inflating: DIV2K_train_HR/0461.png  \n","  inflating: DIV2K_train_HR/0774.png  \n","  inflating: DIV2K_train_HR/0308.png  \n","  inflating: DIV2K_train_HR/0368.png  \n","  inflating: DIV2K_train_HR/0341.png  \n","  inflating: DIV2K_train_HR/0535.png  \n","  inflating: DIV2K_train_HR/0585.png  \n","  inflating: DIV2K_train_HR/0004.png  \n","  inflating: DIV2K_train_HR/0496.png  \n","  inflating: DIV2K_train_HR/0662.png  \n","  inflating: DIV2K_train_HR/0173.png  \n","  inflating: DIV2K_train_HR/0200.png  \n","  inflating: DIV2K_train_HR/0752.png  \n","  inflating: DIV2K_train_HR/0106.png  \n","  inflating: DIV2K_train_HR/0520.png  \n","  inflating: DIV2K_train_HR/0519.png  \n","  inflating: DIV2K_train_HR/0157.png  \n","  inflating: DIV2K_train_HR/0552.png  \n","  inflating: DIV2K_train_HR/0735.png  \n","  inflating: DIV2K_train_HR/0362.png  \n","  inflating: DIV2K_train_HR/0410.png  \n","  inflating: DIV2K_train_HR/0286.png  \n","  inflating: DIV2K_train_HR/0627.png  \n","  inflating: DIV2K_train_HR/0557.png  \n","  inflating: DIV2K_train_HR/0266.png  \n","  inflating: DIV2K_train_HR/0252.png  \n","  inflating: DIV2K_train_HR/0206.png  \n","  inflating: DIV2K_train_HR/0330.png  \n","  inflating: DIV2K_train_HR/0088.png  \n","  inflating: DIV2K_train_HR/0728.png  \n","  inflating: DIV2K_train_HR/0641.png  \n","  inflating: DIV2K_train_HR/0350.png  \n","  inflating: DIV2K_train_HR/0083.png  \n","  inflating: DIV2K_train_HR/0682.png  \n","  inflating: DIV2K_train_HR/0549.png  \n","  inflating: DIV2K_train_HR/0564.png  \n","  inflating: DIV2K_train_HR/0476.png  \n","  inflating: DIV2K_train_HR/0760.png  \n","  inflating: DIV2K_train_HR/0629.png  \n","  inflating: DIV2K_train_HR/0630.png  \n","  inflating: DIV2K_train_HR/0032.png  \n","  inflating: DIV2K_train_HR/0581.png  \n","  inflating: DIV2K_train_HR/0056.png  \n","  inflating: DIV2K_train_HR/0040.png  \n","  inflating: DIV2K_train_HR/0169.png  \n","  inflating: DIV2K_train_HR/0400.png  \n","  inflating: DIV2K_train_HR/0172.png  \n","  inflating: DIV2K_train_HR/0182.png  \n","  inflating: DIV2K_train_HR/0269.png  \n","  inflating: DIV2K_train_HR/0612.png  \n","  inflating: DIV2K_train_HR/0649.png  \n","  inflating: DIV2K_train_HR/0311.png  \n","  inflating: DIV2K_train_HR/0723.png  \n","  inflating: DIV2K_train_HR/0166.png  \n","  inflating: DIV2K_train_HR/0155.png  \n","  inflating: DIV2K_train_HR/0072.png  \n","  inflating: DIV2K_train_HR/0149.png  \n","  inflating: DIV2K_train_HR/0425.png  \n","  inflating: DIV2K_train_HR/0715.png  \n","  inflating: DIV2K_train_HR/0670.png  \n","  inflating: DIV2K_train_HR/0460.png  \n","  inflating: DIV2K_train_HR/0748.png  \n","  inflating: DIV2K_train_HR/0147.png  \n","  inflating: DIV2K_train_HR/0602.png  \n","  inflating: DIV2K_train_HR/0610.png  \n","  inflating: DIV2K_train_HR/0479.png  \n","  inflating: DIV2K_train_HR/0603.png  \n","  inflating: DIV2K_train_HR/0043.png  \n","  inflating: DIV2K_train_HR/0190.png  \n","  inflating: DIV2K_train_HR/0503.png  \n","  inflating: DIV2K_train_HR/0055.png  \n","  inflating: DIV2K_train_HR/0337.png  \n","  inflating: DIV2K_train_HR/0453.png  \n","  inflating: DIV2K_train_HR/0219.png  \n","  inflating: DIV2K_train_HR/0548.png  \n","  inflating: DIV2K_train_HR/0661.png  \n","  inflating: DIV2K_train_HR/0718.png  \n","  inflating: DIV2K_train_HR/0489.png  \n","  inflating: DIV2K_train_HR/0775.png  \n","  inflating: DIV2K_train_HR/0323.png  \n","  inflating: DIV2K_train_HR/0664.png  \n","  inflating: DIV2K_train_HR/0002.png  \n","  inflating: DIV2K_train_HR/0127.png  \n","  inflating: DIV2K_train_HR/0322.png  \n","  inflating: DIV2K_train_HR/0640.png  \n","  inflating: DIV2K_train_HR/0473.png  \n","  inflating: DIV2K_train_HR/0730.png  \n","  inflating: DIV2K_train_HR/0008.png  \n","  inflating: DIV2K_train_HR/0486.png  \n","  inflating: DIV2K_train_HR/0597.png  \n","  inflating: DIV2K_train_HR/0064.png  \n","  inflating: DIV2K_train_HR/0068.png  \n","  inflating: DIV2K_train_HR/0510.png  \n","  inflating: DIV2K_train_HR/0594.png  \n","  inflating: DIV2K_train_HR/0685.png  \n","  inflating: DIV2K_train_HR/0497.png  \n","  inflating: DIV2K_train_HR/0637.png  \n","  inflating: DIV2K_train_HR/0332.png  \n","  inflating: DIV2K_train_HR/0208.png  \n","  inflating: DIV2K_train_HR/0241.png  \n","  inflating: DIV2K_train_HR/0201.png  \n","  inflating: DIV2K_train_HR/0044.png  \n","  inflating: DIV2K_train_HR/0141.png  \n","  inflating: DIV2K_train_HR/0381.png  \n","  inflating: DIV2K_train_HR/0412.png  \n","  inflating: DIV2K_train_HR/0035.png  \n","  inflating: DIV2K_train_HR/0049.png  \n","  inflating: DIV2K_train_HR/0181.png  \n","  inflating: DIV2K_train_HR/0340.png  \n","  inflating: DIV2K_train_HR/0272.png  \n","  inflating: DIV2K_train_HR/0279.png  \n","  inflating: DIV2K_train_HR/0307.png  \n","  inflating: DIV2K_train_HR/0733.png  \n","  inflating: DIV2K_train_HR/0250.png  \n","  inflating: DIV2K_train_HR/0739.png  \n","  inflating: DIV2K_train_HR/0654.png  \n","  inflating: DIV2K_train_HR/0343.png  \n","  inflating: DIV2K_train_HR/0422.png  \n","  inflating: DIV2K_train_HR/0297.png  \n","  inflating: DIV2K_train_HR/0360.png  \n","  inflating: DIV2K_train_HR/0099.png  \n","  inflating: DIV2K_train_HR/0541.png  \n","  inflating: DIV2K_train_HR/0616.png  \n","  inflating: DIV2K_train_HR/0352.png  \n","  inflating: DIV2K_train_HR/0092.png  \n","  inflating: DIV2K_train_HR/0528.png  \n","  inflating: DIV2K_train_HR/0483.png  \n","  inflating: DIV2K_train_HR/0631.png  \n","  inflating: DIV2K_train_HR/0134.png  \n","  inflating: DIV2K_train_HR/0625.png  \n","  inflating: DIV2K_train_HR/0530.png  \n","  inflating: DIV2K_train_HR/0454.png  \n","  inflating: DIV2K_train_HR/0624.png  \n","  inflating: DIV2K_train_HR/0501.png  \n","  inflating: DIV2K_train_HR/0038.png  \n","  inflating: DIV2K_train_HR/0365.png  \n","  inflating: DIV2K_train_HR/0789.png  \n","  inflating: DIV2K_train_HR/0010.png  \n","  inflating: DIV2K_train_HR/0543.png  \n","  inflating: DIV2K_train_HR/0635.png  \n","  inflating: DIV2K_train_HR/0418.png  \n","  inflating: DIV2K_train_HR/0159.png  \n","  inflating: DIV2K_train_HR/0689.png  \n","  inflating: DIV2K_train_HR/0429.png  \n","  inflating: DIV2K_train_HR/0276.png  \n","  inflating: DIV2K_train_HR/0255.png  \n","  inflating: DIV2K_train_HR/0293.png  \n","  inflating: DIV2K_train_HR/0327.png  \n","  inflating: DIV2K_train_HR/0488.png  \n","  inflating: DIV2K_train_HR/0244.png  \n","  inflating: DIV2K_train_HR/0721.png  \n","  inflating: DIV2K_train_HR/0652.png  \n","  inflating: DIV2K_train_HR/0779.png  \n","  inflating: DIV2K_train_HR/0687.png  \n","  inflating: DIV2K_train_HR/0326.png  \n","  inflating: DIV2K_train_HR/0161.png  \n","  inflating: DIV2K_train_HR/0498.png  \n","  inflating: DIV2K_train_HR/0264.png  \n","  inflating: DIV2K_train_HR/0136.png  \n","  inflating: DIV2K_train_HR/0006.png  \n","  inflating: DIV2K_train_HR/0741.png  \n","  inflating: DIV2K_train_HR/0421.png  \n","  inflating: DIV2K_train_HR/0229.png  \n","  inflating: DIV2K_train_HR/0373.png  \n","  inflating: DIV2K_train_HR/0703.png  \n","  inflating: DIV2K_train_HR/0516.png  \n","  inflating: DIV2K_train_HR/0234.png  \n","  inflating: DIV2K_train_HR/0405.png  \n","  inflating: DIV2K_train_HR/0763.png  \n","  inflating: DIV2K_train_HR/0619.png  \n","  inflating: DIV2K_train_HR/0138.png  \n","  inflating: DIV2K_train_HR/0513.png  \n","  inflating: DIV2K_train_HR/0432.png  \n","  inflating: DIV2K_train_HR/0177.png  \n","  inflating: DIV2K_train_HR/0017.png  \n","  inflating: DIV2K_train_HR/0736.png  \n","  inflating: DIV2K_train_HR/0459.png  \n","  inflating: DIV2K_train_HR/0505.png  \n","  inflating: DIV2K_train_HR/0397.png  \n","  inflating: DIV2K_train_HR/0591.png  \n","  inflating: DIV2K_train_HR/0196.png  \n","  inflating: DIV2K_train_HR/0724.png  \n","  inflating: DIV2K_train_HR/0740.png  \n","  inflating: DIV2K_train_HR/0223.png  \n","  inflating: DIV2K_train_HR/0442.png  \n","  inflating: DIV2K_train_HR/0165.png  \n","  inflating: DIV2K_train_HR/0302.png  \n","  inflating: DIV2K_train_HR/0386.png  \n","  inflating: DIV2K_train_HR/0601.png  \n","  inflating: DIV2K_train_HR/0370.png  \n","  inflating: DIV2K_train_HR/0647.png  \n","  inflating: DIV2K_train_HR/0267.png  \n","  inflating: DIV2K_train_HR/0380.png  \n","  inflating: DIV2K_train_HR/0441.png  \n","  inflating: DIV2K_train_HR/0037.png  \n","  inflating: DIV2K_train_HR/0678.png  \n","  inflating: DIV2K_train_HR/0304.png  \n","  inflating: DIV2K_train_HR/0494.png  \n","  inflating: DIV2K_train_HR/0028.png  \n","  inflating: DIV2K_train_HR/0613.png  \n","  inflating: DIV2K_train_HR/0257.png  \n","  inflating: DIV2K_train_HR/0100.png  \n","  inflating: DIV2K_train_HR/0097.png  \n","  inflating: DIV2K_train_HR/0604.png  \n","  inflating: DIV2K_train_HR/0023.png  \n","  inflating: DIV2K_train_HR/0782.png  \n","  inflating: DIV2K_train_HR/0446.png  \n","  inflating: DIV2K_train_HR/0378.png  \n","  inflating: DIV2K_train_HR/0411.png  \n","  inflating: DIV2K_train_HR/0320.png  \n","  inflating: DIV2K_train_HR/0390.png  \n","  inflating: DIV2K_train_HR/0148.png  \n","  inflating: DIV2K_train_HR/0577.png  \n","  inflating: DIV2K_train_HR/0684.png  \n","  inflating: DIV2K_train_HR/0595.png  \n","  inflating: DIV2K_train_HR/0765.png  \n","  inflating: DIV2K_train_HR/0203.png  \n","  inflating: DIV2K_train_HR/0288.png  \n","  inflating: DIV2K_train_HR/0058.png  \n","  inflating: DIV2K_train_HR/0790.png  \n","  inflating: DIV2K_train_HR/0605.png  \n","  inflating: DIV2K_train_HR/0248.png  \n","  inflating: DIV2K_train_HR/0467.png  \n","  inflating: DIV2K_train_HR/0210.png  \n","  inflating: DIV2K_train_HR/0517.png  \n","  inflating: DIV2K_train_HR/0707.png  \n","  inflating: DIV2K_train_HR/0566.png  \n","  inflating: DIV2K_train_HR/0224.png  \n","  inflating: DIV2K_train_HR/0114.png  \n","  inflating: DIV2K_train_HR/0761.png  \n","  inflating: DIV2K_train_HR/0468.png  \n","  inflating: DIV2K_train_HR/0716.png  \n","  inflating: DIV2K_train_HR/0420.png  \n","  inflating: DIV2K_train_HR/0669.png  \n","  inflating: DIV2K_train_HR/0375.png  \n","  inflating: DIV2K_train_HR/0140.png  \n","  inflating: DIV2K_train_HR/0792.png  \n","  inflating: DIV2K_train_HR/0240.png  \n","  inflating: DIV2K_train_HR/0546.png  \n","  inflating: DIV2K_train_HR/0235.png  \n","  inflating: DIV2K_train_HR/0077.png  \n","  inflating: DIV2K_train_HR/0260.png  \n","  inflating: DIV2K_train_HR/0212.png  \n","  inflating: DIV2K_train_HR/0584.png  \n","  inflating: DIV2K_train_HR/0633.png  \n","  inflating: DIV2K_train_HR/0060.png  \n","  inflating: DIV2K_train_HR/0164.png  \n","  inflating: DIV2K_train_HR/0622.png  \n","  inflating: DIV2K_train_HR/0105.png  \n","  inflating: DIV2K_train_HR/0005.png  \n","  inflating: DIV2K_train_HR/0679.png  \n","  inflating: DIV2K_train_HR/0089.png  \n","  inflating: DIV2K_train_HR/0466.png  \n","  inflating: DIV2K_train_HR/0645.png  \n","  inflating: DIV2K_train_HR/0301.png  \n","  inflating: DIV2K_train_HR/0499.png  \n","  inflating: DIV2K_train_HR/0020.png  \n","  inflating: DIV2K_train_HR/0070.png  \n","  inflating: DIV2K_train_HR/0404.png  \n","  inflating: DIV2K_train_HR/0749.png  \n","  inflating: DIV2K_train_HR/0770.png  \n","  inflating: DIV2K_train_HR/0772.png  \n","  inflating: DIV2K_train_HR/0450.png  \n","  inflating: DIV2K_train_HR/0120.png  \n","  inflating: DIV2K_train_HR/0653.png  \n","  inflating: DIV2K_train_HR/0563.png  \n","  inflating: DIV2K_train_HR/0171.png  \n","  inflating: DIV2K_train_HR/0784.png  \n","  inflating: DIV2K_train_HR/0688.png  \n","  inflating: DIV2K_train_HR/0045.png  \n","  inflating: DIV2K_train_HR/0066.png  \n","  inflating: DIV2K_train_HR/0583.png  \n","  inflating: DIV2K_train_HR/0632.png  \n","  inflating: DIV2K_train_HR/0512.png  \n","  inflating: DIV2K_train_HR/0767.png  \n","  inflating: DIV2K_train_HR/0623.png  \n","  inflating: DIV2K_train_HR/0406.png  \n","  inflating: DIV2K_train_HR/0419.png  \n","  inflating: DIV2K_train_HR/0273.png  \n","  inflating: DIV2K_train_HR/0198.png  \n","  inflating: DIV2K_train_HR/0750.png  \n","  inflating: DIV2K_train_HR/0220.png  \n","  inflating: DIV2K_train_HR/0482.png  \n","  inflating: DIV2K_train_HR/0407.png  \n","  inflating: DIV2K_train_HR/0704.png  \n","  inflating: DIV2K_train_HR/0547.png  \n","  inflating: DIV2K_train_HR/0589.png  \n","  inflating: DIV2K_train_HR/0012.png  \n","  inflating: DIV2K_train_HR/0150.png  \n","  inflating: DIV2K_train_HR/0481.png  \n","  inflating: DIV2K_train_HR/0357.png  \n","  inflating: DIV2K_train_HR/0677.png  \n","  inflating: DIV2K_train_HR/0315.png  \n","  inflating: DIV2K_train_HR/0394.png  \n","  inflating: DIV2K_train_HR/0160.png  \n","  inflating: DIV2K_train_HR/0667.png  \n","  inflating: DIV2K_train_HR/0568.png  \n","  inflating: DIV2K_train_HR/0435.png  \n","  inflating: DIV2K_train_HR/0606.png  \n","  inflating: DIV2K_train_HR/0464.png  \n","  inflating: DIV2K_train_HR/0364.png  \n","  inflating: DIV2K_train_HR/0245.png  \n","  inflating: DIV2K_train_HR/0508.png  \n","  inflating: DIV2K_train_HR/0356.png  \n","  inflating: DIV2K_train_HR/0135.png  \n","  inflating: DIV2K_train_HR/0146.png  \n","  inflating: DIV2K_train_HR/0574.png  \n","  inflating: DIV2K_train_HR/0698.png  \n","  inflating: DIV2K_train_HR/0222.png  \n","  inflating: DIV2K_train_HR/0261.png  \n","  inflating: DIV2K_train_HR/0444.png  \n","  inflating: DIV2K_train_HR/0078.png  \n","  inflating: DIV2K_train_HR/0123.png  \n","  inflating: DIV2K_train_HR/0797.png  \n","  inflating: DIV2K_train_HR/0274.png  \n","  inflating: DIV2K_train_HR/0225.png  \n","  inflating: DIV2K_train_HR/0180.png  \n","  inflating: DIV2K_train_HR/0325.png  \n","  inflating: DIV2K_train_HR/0372.png  \n","  inflating: DIV2K_train_HR/0029.png  \n","  inflating: DIV2K_train_HR/0318.png  \n","  inflating: DIV2K_train_HR/0452.png  \n","  inflating: DIV2K_train_HR/0115.png  \n","  inflating: DIV2K_train_HR/0423.png  \n","  inflating: DIV2K_train_HR/0615.png  \n","  inflating: DIV2K_train_HR/0672.png  \n","  inflating: DIV2K_train_HR/0231.png  \n","  inflating: DIV2K_train_HR/0731.png  \n","  inflating: DIV2K_train_HR/0389.png  \n","  inflating: DIV2K_train_HR/0680.png  \n","  inflating: DIV2K_train_HR/0329.png  \n","  inflating: DIV2K_train_HR/0663.png  \n","  inflating: DIV2K_train_HR/0659.png  \n","  inflating: DIV2K_train_HR/0292.png  \n","  inflating: DIV2K_train_HR/0284.png  \n","  inflating: DIV2K_train_HR/0133.png  \n","  inflating: DIV2K_train_HR/0727.png  \n","  inflating: DIV2K_train_HR/0445.png  \n","  inflating: DIV2K_train_HR/0139.png  \n","  inflating: DIV2K_train_HR/0298.png  \n","  inflating: DIV2K_train_HR/0282.png  \n","  inflating: DIV2K_train_HR/0778.png  \n","  inflating: DIV2K_train_HR/0565.png  \n","  inflating: DIV2K_train_HR/0485.png  \n","  inflating: DIV2K_train_HR/0495.png  \n","  inflating: DIV2K_train_HR/0215.png  \n","  inflating: DIV2K_train_HR/0694.png  \n","  inflating: DIV2K_train_HR/0321.png  \n","  inflating: DIV2K_train_HR/0094.png  \n","  inflating: DIV2K_train_HR/0598.png  \n","  inflating: DIV2K_train_HR/0430.png  \n","  inflating: DIV2K_train_HR/0021.png  \n","  inflating: DIV2K_train_HR/0036.png  \n","  inflating: DIV2K_train_HR/0188.png  \n","  inflating: DIV2K_train_HR/0334.png  \n","  inflating: DIV2K_train_HR/0759.png  \n","  inflating: DIV2K_train_HR/0217.png  \n","  inflating: DIV2K_train_HR/0562.png  \n","  inflating: DIV2K_train_HR/0124.png  \n","  inflating: DIV2K_train_HR/0690.png  \n","  inflating: DIV2K_train_HR/0385.png  \n","  inflating: DIV2K_train_HR/0695.png  \n","  inflating: DIV2K_train_HR/0708.png  \n","  inflating: DIV2K_train_HR/0745.png  \n","  inflating: DIV2K_train_HR/0007.png  \n","  inflating: DIV2K_train_HR/0226.png  \n","  inflating: DIV2K_train_HR/0256.png  \n","  inflating: DIV2K_train_HR/0673.png  \n","  inflating: DIV2K_train_HR/0451.png  \n","  inflating: DIV2K_train_HR/0143.png  \n","  inflating: DIV2K_train_HR/0403.png  \n","  inflating: DIV2K_train_HR/0125.png  \n","  inflating: DIV2K_train_HR/0132.png  \n","  inflating: DIV2K_train_HR/0644.png  \n","  inflating: DIV2K_train_HR/0796.png  \n","  inflating: DIV2K_train_HR/0076.png  \n","  inflating: DIV2K_train_HR/0211.png  \n","  inflating: DIV2K_train_HR/0676.png  \n","  inflating: DIV2K_train_HR/0121.png  \n","  inflating: DIV2K_train_HR/0415.png  \n","  inflating: DIV2K_train_HR/0536.png  \n","  inflating: DIV2K_train_HR/0620.png  \n","  inflating: DIV2K_train_HR/0331.png  \n","  inflating: DIV2K_train_HR/0277.png  \n","  inflating: DIV2K_train_HR/0611.png  \n","  inflating: DIV2K_train_HR/0262.png  \n","  inflating: DIV2K_train_HR/0305.png  \n","  inflating: DIV2K_train_HR/0521.png  \n","  inflating: DIV2K_train_HR/0221.png  \n","  inflating: DIV2K_train_HR/0699.png  \n","  inflating: DIV2K_train_HR/0743.png  \n","  inflating: DIV2K_train_HR/0742.png  \n","  inflating: DIV2K_train_HR/0111.png  \n","  inflating: DIV2K_train_HR/0480.png  \n","  inflating: DIV2K_train_HR/0720.png  \n","  inflating: DIV2K_train_HR/0402.png  \n","  inflating: DIV2K_train_HR/0561.png  \n","  inflating: DIV2K_train_HR/0729.png  \n","  inflating: DIV2K_train_HR/0296.png  \n","  inflating: DIV2K_train_HR/0379.png  \n","  inflating: DIV2K_train_HR/0014.png  \n","  inflating: DIV2K_train_HR/0714.png  \n","  inflating: DIV2K_train_HR/0754.png  \n","  inflating: DIV2K_train_HR/0634.png  \n","  inflating: DIV2K_train_HR/0725.png  \n","  inflating: DIV2K_train_HR/0309.png  \n","  inflating: DIV2K_train_HR/0197.png  \n","  inflating: DIV2K_train_HR/0039.png  \n","  inflating: DIV2K_train_HR/0696.png  \n","  inflating: DIV2K_train_HR/0758.png  \n","  inflating: DIV2K_train_HR/0599.png  \n","  inflating: DIV2K_train_HR/0228.png  \n","  inflating: DIV2K_train_HR/0712.png  \n","  inflating: DIV2K_train_HR/0539.png  \n","  inflating: DIV2K_train_HR/0781.png  \n","  inflating: DIV2K_train_HR/0009.png  \n","  inflating: DIV2K_train_HR/0145.png  \n","  inflating: DIV2K_train_HR/0527.png  \n","  inflating: DIV2K_train_HR/0263.png  \n","  inflating: DIV2K_train_HR/0122.png  \n","  inflating: DIV2K_train_HR/0506.png  \n","  inflating: DIV2K_train_HR/0363.png  \n","  inflating: DIV2K_train_HR/0249.png  \n","  inflating: DIV2K_train_HR/0104.png  \n","  inflating: DIV2K_train_HR/0800.png  \n","  inflating: DIV2K_train_HR/0214.png  \n","  inflating: DIV2K_train_HR/0658.png  \n","  inflating: DIV2K_train_HR/0399.png  \n","  inflating: DIV2K_train_HR/0572.png  \n","  inflating: DIV2K_train_HR/0204.png  \n","  inflating: DIV2K_train_HR/0651.png  \n","  inflating: DIV2K_train_HR/0061.png  \n","  inflating: DIV2K_train_HR/0026.png  \n","  inflating: DIV2K_train_HR/0300.png  \n","  inflating: DIV2K_train_HR/0162.png  \n","  inflating: DIV2K_train_HR/0478.png  \n","  inflating: DIV2K_train_HR/0022.png  \n","  inflating: DIV2K_train_HR/0079.png  \n","  inflating: DIV2K_train_HR/0285.png  \n","  inflating: DIV2K_train_HR/0511.png  \n","  inflating: DIV2K_train_HR/0025.png  \n","  inflating: DIV2K_train_HR/0428.png  \n","  inflating: DIV2K_train_HR/0436.png  \n","  inflating: DIV2K_train_HR/0324.png  \n","  inflating: DIV2K_train_HR/0447.png  \n","  inflating: DIV2K_train_HR/0457.png  \n","  inflating: DIV2K_train_HR/0424.png  \n","  inflating: DIV2K_train_HR/0675.png  \n","  inflating: DIV2K_train_HR/0469.png  \n","  inflating: DIV2K_train_HR/0090.png  \n","  inflating: DIV2K_train_HR/0179.png  \n","  inflating: DIV2K_train_HR/0771.png  \n","  inflating: DIV2K_train_HR/0431.png  \n","  inflating: DIV2K_train_HR/0726.png  \n","  inflating: DIV2K_train_HR/0609.png  \n","  inflating: DIV2K_train_HR/0184.png  \n","  inflating: DIV2K_train_HR/0747.png  \n","  inflating: DIV2K_train_HR/0154.png  \n","  inflating: DIV2K_train_HR/0391.png  \n","  inflating: DIV2K_train_HR/0573.png  \n","  inflating: DIV2K_train_HR/0071.png  \n","  inflating: DIV2K_train_HR/0798.png  \n","  inflating: DIV2K_train_HR/0693.png  \n","  inflating: DIV2K_train_HR/0280.png  \n","  inflating: DIV2K_train_HR/0414.png  \n","  inflating: DIV2K_train_HR/0119.png  \n","  inflating: DIV2K_train_HR/0757.png  \n","  inflating: DIV2K_train_HR/0762.png  \n","  inflating: DIV2K_train_HR/0734.png  \n","  inflating: DIV2K_train_HR/0001.png  \n","  inflating: DIV2K_train_HR/0265.png  \n","  inflating: DIV2K_train_HR/0643.png  \n","  inflating: DIV2K_train_HR/0567.png  \n","  inflating: DIV2K_train_HR/0130.png  \n","  inflating: DIV2K_train_HR/0580.png  \n","  inflating: DIV2K_train_HR/0463.png  \n","  inflating: DIV2K_train_HR/0218.png  \n","  inflating: DIV2K_train_HR/0769.png  \n","  inflating: DIV2K_train_HR/0507.png  \n","  inflating: DIV2K_train_HR/0013.png  \n","  inflating: DIV2K_train_HR/0233.png  \n","  inflating: DIV2K_train_HR/0087.png  \n","  inflating: DIV2K_train_HR/0093.png  \n","  inflating: DIV2K_train_HR/0709.png  \n","  inflating: DIV2K_train_HR/0027.png  \n","  inflating: DIV2K_train_HR/0570.png  \n","  inflating: DIV2K_train_HR/0342.png  \n","  inflating: DIV2K_train_HR/0011.png  \n","  inflating: DIV2K_train_HR/0287.png  \n","  inflating: DIV2K_train_HR/0524.png  \n","  inflating: DIV2K_train_HR/0791.png  \n","  inflating: DIV2K_train_HR/0701.png  \n","  inflating: DIV2K_train_HR/0783.png  \n","  inflating: DIV2K_train_HR/0349.png  \n","  inflating: DIV2K_train_HR/0766.png  \n","  inflating: DIV2K_train_HR/0232.png  \n","  inflating: DIV2K_train_HR/0314.png  \n","  inflating: DIV2K_train_HR/0303.png  \n","  inflating: DIV2K_train_HR/0697.png  \n","  inflating: DIV2K_train_HR/0514.png  \n","  inflating: DIV2K_train_HR/0377.png  \n","  inflating: DIV2K_train_HR/0085.png  \n","  inflating: DIV2K_train_HR/0113.png  \n","  inflating: DIV2K_train_HR/0540.png  \n","  inflating: DIV2K_train_HR/0383.png  \n","  inflating: DIV2K_train_HR/0243.png  \n","  inflating: DIV2K_train_HR/0086.png  \n","  inflating: DIV2K_train_HR/0091.png  \n","  inflating: DIV2K_train_HR/0151.png  \n","  inflating: DIV2K_train_HR/0502.png  \n","  inflating: DIV2K_train_HR/0294.png  \n","  inflating: DIV2K_train_HR/0281.png  \n","  inflating: DIV2K_train_HR/0656.png  \n","  inflating: DIV2K_train_HR/0500.png  \n","  inflating: DIV2K_train_HR/0237.png  \n","  inflating: DIV2K_train_HR/0387.png  \n","  inflating: DIV2K_train_HR/0178.png  \n","  inflating: DIV2K_train_HR/0518.png  \n","  inflating: DIV2K_train_HR/0239.png  \n","  inflating: DIV2K_train_HR/0131.png  \n","  inflating: DIV2K_train_HR/0655.png  \n","  inflating: DIV2K_train_HR/0417.png  \n","  inflating: DIV2K_train_HR/0776.png  \n","  inflating: DIV2K_train_HR/0560.png  \n","  inflating: DIV2K_train_HR/0737.png  \n","  inflating: DIV2K_train_HR/0048.png  \n","  inflating: DIV2K_train_HR/0128.png  \n","  inflating: DIV2K_train_HR/0052.png  \n","  inflating: DIV2K_train_HR/0137.png  \n","  inflating: DIV2K_train_HR/0686.png  \n","  inflating: DIV2K_train_HR/0053.png  \n","  inflating: DIV2K_train_HR/0665.png  \n","  inflating: DIV2K_train_HR/0691.png  \n","  inflating: DIV2K_train_HR/0167.png  \n","  inflating: DIV2K_train_HR/0313.png  \n","  inflating: DIV2K_train_HR/0531.png  \n","  inflating: DIV2K_train_HR/0569.png  \n","  inflating: DIV2K_train_HR/0553.png  \n","  inflating: DIV2K_train_HR/0047.png  \n","  inflating: DIV2K_train_HR/0096.png  \n","  inflating: DIV2K_train_HR/0756.png  \n","  inflating: DIV2K_train_HR/0440.png  \n","  inflating: DIV2K_train_HR/0199.png  \n","  inflating: DIV2K_train_HR/0283.png  \n","  inflating: DIV2K_train_HR/0247.png  \n","  inflating: DIV2K_train_HR/0024.png  \n","  inflating: DIV2K_train_HR/0193.png  \n","  inflating: DIV2K_train_HR/0084.png  \n","  inflating: DIV2K_train_HR/0102.png  \n","  inflating: DIV2K_train_HR/0551.png  \n","  inflating: DIV2K_train_HR/0575.png  \n","  inflating: DIV2K_train_HR/0477.png  \n","  inflating: DIV2K_train_HR/0098.png  \n","  inflating: DIV2K_train_HR/0554.png  \n","  inflating: DIV2K_train_HR/0189.png  \n","  inflating: DIV2K_train_HR/0717.png  \n","  inflating: DIV2K_train_HR/0732.png  \n","  inflating: DIV2K_train_HR/0702.png  \n","  inflating: DIV2K_train_HR/0183.png  \n","  inflating: DIV2K_train_HR/0448.png  \n","  inflating: DIV2K_train_HR/0455.png  \n","  inflating: DIV2K_train_HR/0367.png  \n","  inflating: DIV2K_train_HR/0251.png  \n","  inflating: DIV2K_train_HR/0744.png  \n","  inflating: DIV2K_train_HR/0785.png  \n","  inflating: DIV2K_train_HR/0067.png  \n","  inflating: DIV2K_train_HR/0163.png  \n","  inflating: DIV2K_train_HR/0751.png  \n","  inflating: DIV2K_train_HR/0299.png  \n","  inflating: DIV2K_train_HR/0129.png  \n","  inflating: DIV2K_train_HR/0291.png  \n","  inflating: DIV2K_train_HR/0607.png  \n","  inflating: DIV2K_train_HR/0242.png  \n","  inflating: DIV2K_train_HR/0107.png  \n","  inflating: DIV2K_train_HR/0175.png  \n","  inflating: DIV2K_train_HR/0753.png  \n","  inflating: DIV2K_train_HR/0278.png  \n","  inflating: DIV2K_train_HR/0369.png  \n","  inflating: DIV2K_train_HR/0571.png  \n","  inflating: DIV2K_train_HR/0202.png  \n","  inflating: DIV2K_train_HR/0030.png  \n","  inflating: DIV2K_train_HR/0799.png  \n","  inflating: DIV2K_train_HR/0474.png  \n","  inflating: DIV2K_train_HR/0491.png  \n","  inflating: DIV2K_train_HR/0638.png  \n","  inflating: DIV2K_train_HR/0600.png  \n","  inflating: DIV2K_train_HR/0596.png  \n","  inflating: DIV2K_train_HR/0059.png  \n","  inflating: DIV2K_train_HR/0186.png  \n","  inflating: DIV2K_train_HR/0509.png  \n","  inflating: DIV2K_train_HR/0529.png  \n","  inflating: DIV2K_train_HR/0787.png  \n","  inflating: DIV2K_train_HR/0382.png  \n","  inflating: DIV2K_train_HR/0777.png  \n","  inflating: DIV2K_train_HR/0109.png  \n","  inflating: DIV2K_train_HR/0227.png  \n","  inflating: DIV2K_train_HR/0388.png  \n","  inflating: DIV2K_train_HR/0618.png  \n","  inflating: DIV2K_train_HR/0681.png  \n","  inflating: DIV2K_train_HR/0205.png  \n","  inflating: DIV2K_train_HR/0472.png  \n","  inflating: DIV2K_train_HR/0306.png  \n","  inflating: DIV2K_train_HR/0361.png  \n","  inflating: DIV2K_train_HR/0738.png  \n","  inflating: DIV2K_train_HR/0230.png  \n","  inflating: DIV2K_train_HR/0081.png  \n","  inflating: DIV2K_train_HR/0095.png  \n","  inflating: DIV2K_train_HR/0449.png  \n","  inflating: DIV2K_train_HR/0626.png  \n","  inflating: DIV2K_train_HR/0065.png  \n","  inflating: DIV2K_train_HR/0443.png  \n","  inflating: DIV2K_train_HR/0275.png  \n","  inflating: DIV2K_train_HR/0542.png  \n","  inflating: DIV2K_train_HR/0484.png  \n","  inflating: DIV2K_train_HR/0359.png  \n","  inflating: DIV2K_train_HR/0773.png  \n","  inflating: DIV2K_train_HR/0434.png  \n","  inflating: DIV2K_train_HR/0544.png  \n","  inflating: DIV2K_train_HR/0416.png  \n","  inflating: DIV2K_train_HR/0295.png  \n","  inflating: DIV2K_train_HR/0538.png  \n","  inflating: DIV2K_train_HR/0259.png  \n","  inflating: DIV2K_train_HR/0348.png  \n","  inflating: DIV2K_train_HR/0588.png  \n","  inflating: DIV2K_train_HR/0710.png  \n","  inflating: DIV2K_train_HR/0786.png  \n","  inflating: DIV2K_train_HR/0185.png  \n","  inflating: DIV2K_train_HR/0057.png  \n","  inflating: DIV2K_train_HR/0487.png  \n","  inflating: DIV2K_train_HR/0683.png  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5pVkigHcYFmX","colab":{}},"source":["#defining cropping image function\n","def crop_center_image(img,new_height,new_width):\n","    w,h,_ = img.shape\n","    old_height = h//2-(new_height//2)\n","    old_width = w//2-(new_width//2)    \n","    return img[old_width:old_width+new_width,old_height:old_height+new_height,:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SNt7ndVFAzbl","colab":{}},"source":["#Resizing the image\n","img_list, img_low_list = [], []\n","for i in os.listdir():\n","  if '.png' in i:\n","    img = cv2.imread(i)\n","    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","    img_crop = crop_center_image(img,256,256)\n","    img_list.append(img_crop)\n","    img_low_list.append(cv2.resize(img_crop,(64,64)))\n","\n","high_reso_imgs = np.array(img_list)\n","low_reso_imgs = np.array(img_low_list)   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"77FZj_g91cq7","colab_type":"code","colab":{}},"source":["os.chdir('/content')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BfQ2pZPIWXf8","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"be31811f-8918-4786-8d86-ad37c270dcae","executionInfo":{"status":"error","timestamp":1575355264431,"user_tz":-330,"elapsed":1915,"user":{"displayName":"Noor Fatima","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mApQYMABtajgCZCy7cF1as2H2UpI9g5drQw9DFD=s64","userId":"06775967229168824100"}}},"source":["plt.figure(figsize = (15,15))\n","plt.subplot(1,2,1)\n","plt.imshow(high_reso_imgs[5])\n","plt.grid('off')\n","plt.axis('off')\n","plt.title('High Resolution')\n","plt.subplot(1,2,2)\n","plt.imshow(cv2.resize(low_reso_imgs[5],(256,256),\n","                      interpolation = cv2.INTER_CUBIC))\n","plt.grid('off')\n","plt.axis('off')\n","_=plt.title('low Resolution X4 (bicubic)')"],"execution_count":28,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-0b126b0a0ef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh_reso_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 0"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAakAAANSCAYAAADf5jGoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAW/klEQVR4nO3cX4jl533f8c/XUpRQx3FCtYGgP5FL\n5TqLU7A7qC6BxsVukXQhXaQECUzqICxIq1AaE1BJcYJylZqmEFDrbKlxE4gVJRdhIQq6SBQEITJa\n40ZYMgpbxbVWCWjjOLoxsaL26cUcl8lmV3NGmt39WOf1goXzO+eZc748zO57zpnf/matFQBo9Lar\nPQAAXIpIAVBLpACoJVIA1BIpAGqJFAC1Do3UzHx6Zl6emS9e4vGZmV+ambMz88zMvP/4xwRgF23z\nTuozSW5/ncfvSHLr5s/9Sf7rmx8LALaI1FrrySR/8TpL7k7yK2vfU0m+e2a+77gGBGB3XXsMz3FD\nkhcPHJ/b3PdnFy6cmfuz/24rb3/72//Re97znmN4eQDaff7zn//ztdaJo37dcURqa2utU0lOJcne\n3t46c+bMlXx5AK6Smfnfb+TrjuPsvpeS3HTg+MbNfQDwphxHpE4n+bHNWX4fSPLKWutvfdQHAEd1\n6Md9M/PZJB9Mcv3MnEvys0m+LUnWWp9K8liSO5OcTfL1JD9+uYYFYLccGqm11r2HPL6S/JtjmwgA\nNlxxAoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQS\nKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACo\nJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgB\nUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2R\nAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBa\nIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQA\ntUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIp\nAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKgl\nUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQ\nS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZEC\noJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQK2tIjUzt8/M8zNzdmYevMjjN8/MEzPzhZl5Zmbu\nPP5RAdg1h0ZqZq5J8nCSO5KcTHLvzJy8YNl/SPLoWut9Se5J8l+Oe1AAds8276RuS3J2rfXCWuvV\nJI8kufuCNSvJd21uvzPJnx7fiADsqm0idUOSFw8cn9vcd9DPJfnIzJxL8liSn7zYE83M/TNzZmbO\nnD9//g2MC8AuOa4TJ+5N8pm11o1J7kzyqzPzt557rXVqrbW31to7ceLEMb00AG9V20TqpSQ3HTi+\ncXPfQfcleTRJ1lp/mOQ7klx/HAMCsLu2idTTSW6dmXfNzHXZPzHi9AVrvpLkQ0kyMz+Q/Uj5PA+A\nN+XQSK21XkvyQJLHk3wp+2fxPTszD83MXZtlH0/ysZn5oySfTfLRtda6XEMDsBuu3WbRWuux7J8Q\ncfC+Txy4/VySHzre0QDYda44AUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZI\nAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAt\nkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqA\nWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokU\nALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQS\nKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACo\nJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgB\nUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2R\nAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBa\nIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQA\ntUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoNZWkZqZ22fm+Zk5OzMP\nXmLNj87MczPz7Mz82vGOCcAuuvawBTNzTZKHk/zzJOeSPD0zp9dazx1Yc2uSf5/kh9ZaX5uZ771c\nAwOwO7Z5J3VbkrNrrRfWWq8meSTJ3Res+ViSh9daX0uStdbLxzsmALtom0jdkOTFA8fnNvcd9O4k\n756ZP5iZp2bm9uMaEIDddejHfUd4nluTfDDJjUmenJkfXGv95cFFM3N/kvuT5Oabbz6mlwbgrWqb\nd1IvJbnpwPGNm/sOOpfk9Frrr9daf5Lkj7Mfrb9hrXVqrbW31to7ceLEG50ZgB2xTaSeTnLrzLxr\nZq5Lck+S0xes+a3sv4vKzFyf/Y//XjjGOQHYQYdGaq31WpIHkjye5EtJHl1rPTszD83MXZtljyf5\n6sw8l+SJJD+91vrq5RoagN0wa62r8sJ7e3vrzJkzV+W1AbiyZubza629o36dK04AUEukAKglUgDU\nEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QA\nqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZI\nAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAt\nkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqA\nWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokU\nALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQS\nKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACo\nJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgB\nUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2R\nAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBa\nIgVALZECoJZIAVBLpACotVWkZub2mXl+Zs7OzIOvs+5HZmbNzN7xjQjArjo0UjNzTZKHk9yR5GSS\ne2fm5EXWvSPJv03yueMeEoDdtM07qduSnF1rvbDWejXJI0nuvsi6n0/yC0n+6hjnA2CHbROpG5K8\neOD43Oa+/29m3p/kprXWbx/jbADsuDd94sTMvC3JLyb5+BZr75+ZMzNz5vz582/2pQF4i9smUi8l\nuenA8Y2b+77pHUnem+T3Z+bLST6Q5PTFTp5Ya51aa+2ttfZOnDjxxqcGYCdsE6mnk9w6M++ameuS\n3JPk9DcfXGu9sta6fq11y1rrliRPJblrrXXmskwMwM44NFJrrdeSPJDk8SRfSvLoWuvZmXloZu66\n3AMCsLuu3WbRWuuxJI9dcN8nLrH2g29+LABwxQkAiokUALVECoBaIgVALZECoJZIAVBLpACoJVIA\n1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEuk\nAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCW\nSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVA\nLZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQK\ngFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJ\nFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDU\nEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QA\nqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZI\nAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAt\nkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqA\nWltFamZun5nnZ+bszDx4kcd/amaem5lnZuZ3Z+b7j39UAHbNoZGamWuSPJzkjiQnk9w7MycvWPaF\nJHtrrX+Y5DeT/MfjHhSA3bPNO6nbkpxda72w1no1ySNJ7j64YK31xFrr65vDp5LceLxjArCLtonU\nDUlePHB8bnPfpdyX5Hcu9sDM3D8zZ2bmzPnz57efEoCddKwnTszMR5LsJfnkxR5fa51aa+2ttfZO\nnDhxnC8NwFvQtVuseSnJTQeOb9zc9zfMzIeT/EySH15rfeN4xgNgl23zTurpJLfOzLtm5rok9yQ5\nfXDBzLwvyS8nuWut9fLxjwnALjo0Umut15I8kOTxJF9K8uha69mZeWhm7tos+2SS70zyGzPzP2fm\n9CWeDgC2ts3HfVlrPZbksQvu+8SB2x8+5rkAwBUnAOglUgDUEikAaokUALVECoBaIgVALZECoJZI\nAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAt\nkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqA\nWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokU\nALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQS\nKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACo\nJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgB\nUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2R\nAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBa\nIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQA\ntUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1Noq\nUjNz+8w8PzNnZ+bBizz+7TPz65vHPzcztxz3oADsnkMjNTPXJHk4yR1JTia5d2ZOXrDsviRfW2v9\n/ST/OckvHPegAOyebd5J3Zbk7FrrhbXWq0keSXL3BWvuTvI/Nrd/M8mHZmaOb0wAdtG1W6y5IcmL\nB47PJfnHl1qz1nptZl5J8neT/PnBRTNzf5L7N4ffmJkvvpGhd9T1uWA/eV3262js19HYr6P7B2/k\ni7aJ1LFZa51KcipJZubMWmvvSr7+tzL7dTT262js19HYr6ObmTNv5Ou2+bjvpSQ3HTi+cXPfRdfM\nzLVJ3pnkq29kIAD4pm0i9XSSW2fmXTNzXZJ7kpy+YM3pJP9qc/tfJvm9tdY6vjEB2EWHfty3+R3T\nA0keT3JNkk+vtZ6dmYeSnFlrnU7y35P86sycTfIX2Q/ZYU69ibl3kf06Gvt1NPbraOzX0b2hPRtv\neABo5YoTANQSKQBqXfZIuaTS0WyxXz81M8/NzDMz87sz8/1XY84Wh+3XgXU/MjNrZnb6tOFt9mtm\nfnTzPfbszPzalZ6xyRZ/H2+emSdm5gubv5N3Xo05W8zMp2fm5Uv9H9jZ90ub/XxmZt5/6JOutS7b\nn+yfaPG/kvy9JNcl+aMkJy9Y86+TfGpz+54kv345Z2r+s+V+/bMkf2dz+yfs1+vv12bdO5I8meSp\nJHtXe+7m/Upya5IvJPmezfH3Xu25y/frVJKf2Nw+meTLV3vuq7xn/zTJ+5N88RKP35nkd5JMkg8k\n+dxhz3m530m5pNLRHLpfa60n1lpf3xw+lf3/t7artvn+SpKfz/71JP/qSg5XaJv9+liSh9daX0uS\ntdbLV3jGJtvs10ryXZvb70zyp1dwvjprrSezf4b3pdyd5FfWvqeSfPfMfN/rPefljtTFLql0w6XW\nrLVeS/LNSyrtom3266D7sv9Tya46dL82HyfctNb67Ss5WKltvr/eneTdM/MHM/PUzNx+xabrs81+\n/VySj8zMuSSPJfnJKzPat6yj/ht3ZS+LxPGZmY8k2Uvyw1d7llYz87Ykv5jko1d5lG8l12b/I78P\nZv9d+pMz84Nrrb+8qlP1ujfJZ9Za/2lm/kn2/7/oe9da//dqD/ZWcbnfSbmk0tFss1+ZmQ8n+Zkk\nd621vnGFZmt02H69I8l7k/z+zHw5+5+Bn97hkye2+f46l+T0Wuuv11p/kuSPsx+tXbTNft2X5NEk\nWWv9YZLvyP7FZ7m4rf6NO+hyR8ollY7m0P2amfcl+eXsB2qXf1+QHLJfa61X1lrXr7VuWWvdkv3f\n4d211npDF7p8C9jm7+NvZf9dVGbm+ux//PfClRyyyDb79ZUkH0qSmfmB7Efq/BWd8lvL6SQ/tjnL\n7wNJXllr/dnrfcFl/bhvXb5LKr0lbblfn0zynUl+Y3N+yVfWWnddtaGvoi33i40t9+vxJP9iZp5L\n8n+S/PRaayc/2dhyvz6e5L/NzL/L/kkUH93hH7IzM5/N/g85129+T/ezSb4tSdZan8r+7+3uTHI2\nydeT/Pihz7nD+wlAOVecAKCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFr/Dyh56Dax8JLRAAAAAElF\nTkSuQmCC\n","text/plain":["<Figure size 1080x1080 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oQzz2MQ7fq6U","colab":{}},"source":["#Creating the model\n","class SRGAN():\n","    def __init__(self,lr_height = 64,lr_width = 64,channels = 3, upscale_factor = 4, generator_lr = 1e-4, discriminator_lr = 1e-4, gan_lr = 1e-4):\n","        self.height_low_reso = lr_height\n","        self.width_low_reso = lr_width\n","\n","        if upscale_factor % 2 != 0:\n","            raise ValueError('Upscale factor is invalid, must be product of 2')\n","\n","        self.upscale_factor = upscale_factor\n","        self.height_high_reso = self.height_low_reso * self.upscale_factor\n","        self.width_high_reso = self.width_low_reso * self.upscale_factor\n","\n","        self.channels = channels\n","        self.shape_low_reso = (self.height_low_reso,self.width_low_reso,self.channels)\n","        self.shape_high_reso = (self.height_high_reso,self.width_high_reso,self.channels)\n","\n","        self.samples = high_reso_imgs.shape[0]\n","\n","        opti_generator = Adam(generator_lr,0.9)\n","        opti_discriminator = Adam(discriminator_lr,0.9)\n","        opti_gan = Adam(gan_lr,0.9) \n","\n","        self.vgg = self.bulid_vgg()\n","\n","        self.discriminator = self.build_discriminator(opti_discriminator)\n","        self.discriminator.trainable = False\n","        self.generator = self.build_generator(opti_generator)\n","        self.srgan = self.build_srgan(opti_gan)\n","\n","    def save_GAN_Model(self,epoch):\n","        self.srgan.save_weights('srgan_weights_epoch_%d.h5' % epoch)\n","\n","\n","    def plotLosses(self,dlosses,glosses,epo):\n","        fig, ax1 = plt.subplots(figsize = (10,12))\n","        color = 'tab:blue'\n","        ax1.plot(dlosses,color = color, label = 'Dis loss')\n","        ax1.set_xlabel('Epoch')\n","        ax1.set_ylabel('Dis loss', color = color)\n","        ax1.tick_params('y',color = color)\n","        color = 'tab:green'\n","        ax2 = ax1.twinx()\n","        ax2.plot(glosses, color = color, label = 'Gen loss')\n","        ax2.set_ylabel('Gen loss', color = color)\n","        ax2.tick_params('y', color = color)\n","        plt.title('Discriminator & Generator Losses')\n","        plt.savefig('Losses_%d.png' % epo)\n","        plt.show()\n","\n","    def gen_pipeline(self, batch_size = 16):\n","        while(1):\n","            indx_high = np.random.randint(0,high_reso_imgs.shape[0]-1,batch_size)\n","            \n","            indx_low = np.random.randint(0,low_reso_imgs.shape[0]-1,batch_size)\n","            \n","            real = np.ones((batch_size,) + self.discriminator.output_shape[1:])\n","            \n","            fake = np.zeros((batch_size,) + self.discriminator.output_shape[1:])\n","            \n","            norm_hr = high_reso_imgs[indx_high]/127.5-1\n","            norm_lr = low_reso_imgs[indx_low]/127.5 -1\n","            yield(norm_hr,real,norm_lr,fake)\n","            \n","    def vgg_pipeline(self, batch_size = 16):\n","      while(1):\n","        indx = np.random.randint(0,high_reso_imgs.shape[0]-1,batch_size)\n","        real = np.ones((batch_size,) + self.discriminator.output_shape[1:])\n","        norm_hr = high_reso_imgs[indx]/127.5-1\n","        norm_lr = low_reso_imgs[indx]/127.5 -1\n","        yield(norm_hr,norm_lr,real)\n","            \n","      \n","    def bulid_vgg(self):\n","        vgg = VGG19(weights = \"imagenet\")\n","#         vgg.summary()\n","        vgg.outputs = [vgg.layers[9].output]\n","        img = Input(shape = self.shape_high_reso)\n","        img_features = vgg(img)\n","        vgg_model = Model(img, img_features)\n","#         for layer in vgg_model.layers:\n","#             layer.trainable = False\n","        vgg_model.compile(loss = 'mse', optimizer = Adam(0.0002,0.5),\n","                         metrics =['acc'])\n","        return vgg_model\n","\n","\n","    def residual_block(self,input_layer):\n","        x = Conv2D(filters = 64, kernel_size = 3, padding = 'same')(input_layer)\n","        x = BatchNormalization(momentum=0.8)(x)\n","        x = PReLU()(x)\n","        x = Conv2D(filters = 64, kernel_size = 3, padding = 'same')(x)\n","        x = BatchNormalization(momentum=0.8)(x)\n","        return Add()([input_layer,x])\n","\n","    def disc_block(self,layer, n_filters, batch_norm = True):\n","        x = Conv2D(filters = n_filters, kernel_size = 3, padding = 'same')(layer)\n","        if batch_norm:\n","            x = BatchNormalization(momentum=0.8)(x)\n","        x = LeakyReLU(alpha=0.2)(x)\n","        x = Conv2D(filters = n_filters, kernel_size = 3,\n","                   strides=2, padding = 'same')(x)\n","        x = BatchNormalization(momentum=0.8)(x)\n","        x = LeakyReLU(alpha=0.2)(x)\n","        return x\n","\n","    def Upsample_Block(self,x_in):\n","        x = Conv2D(filters = 256, kernel_size=3, padding='same')(x_in)\n","        x = self.SubpixelConv2D(2)(x)\n","        return PReLU()(x)\n","      \n","    def SubpixelConv2D(self,scale):\n","        return Lambda(lambda x: tf.depth_to_space(x, scale))\n","  \n","    def build_generator(self,opti_generator,n_blocks = 16):\n","        input_layer = Input(self.shape_low_reso)\n","        \n","        first_layer = Conv2D(filters = 64, kernel_size = 9,\n","                             padding = 'same')(input_layer)\n","        \n","        first_layer = PReLU()(first_layer)\n","        \n","        residual_blocks = self.residual_block(first_layer)\n","        \n","        for _ in range(n_blocks-1):\n","            residual_blocks = self.residual_block(residual_blocks)\n","\n","        output_residual = Conv2D(filters = 64, kernel_size = 3,\n","                             padding = 'same')(residual_blocks)\n","        \n","        output_residual = BatchNormalization(momentum=0.8)(output_residual)\n","        \n","        output_residual = Add()([output_residual,first_layer])\n","               \n","        upsample_layer = self.Upsample_Block(output_residual)\n","        \n","        for _ in range(self.upscale_factor//2-1):\n","            upsample_layer =  self.Upsample_Block(upsample_layer)\n","            \n","        gen_output = Conv2D(filters = 3, kernel_size = 9,\n","                            padding = 'same', activation = 'tanh')(upsample_layer)\n","\n","        gen_model = Model(inputs = input_layer, outputs = gen_output)\n","        gen_model.compile(loss = 'binary_crossentropy', optimizer = opti_generator)\n","\n","        return gen_model\n","\n","    def build_discriminator(self,opti_discriminator,n_blocks = 3, n_filters = 64):\n","        input_layer = Input(self.shape_high_reso)\n","        discriminator_blocks = self.disc_block(input_layer,n_filters,False)\n","        for i in range(n_blocks):\n","            discriminator_blocks = self.disc_block(discriminator_blocks, \n","                                             n_filters = (i+1)*2*n_filters)\n","        \n","        #f_layer = GlobalAveragePooling2D()(discriminator_blocks)\n","        f_layer = Dense(units = 1024)(discriminator_blocks)\n","        f_layer = LeakyReLU(alpha=0.2)(f_layer)\n","        dis_output = Dense(units = 1, activation = 'sigmoid')(f_layer)\n","        disc_model = Model(inputs = input_layer, outputs = dis_output)\n","        disc_model.compile(loss = 'mse', optimizer = opti_discriminator,\n","                          metrics = ['accuracy'])\n","\n","        return disc_model\n","\n","    def build_srgan(self,optimizer):\n","        dis_input = Input(self.shape_high_reso)\n","        gen_input = Input(self.shape_low_reso)\n","\n","        generated_high_reso = self.generator(gen_input)\n","        generated_features = self.vgg(generated_high_reso)\n","        generator_valid = self.discriminator(generated_high_reso)\n","\n","\n","        gan_model = Model(inputs = [gen_input, dis_input], \n","                          outputs = [generator_valid, generated_features])\n","        \n","        for l in gan_model.layers[-1].layers[-1].layers:\n","          l.trainable=False\n","        \n","        gan_model.compile(loss = ['binary_crossentropy','mse'], loss_weights = [1e-2,1], optimizer = 'adam')\n","        gan_model.summary()\n","        \n","        return gan_model\n","\n","\n","    def train(self, epochs, save_interval = 20, batch_size = 16):\n","        pipeline = self.gen_pipeline(batch_size)\n","        vgg_pipeline = self.vgg_pipeline(batch_size)\n","\n","        batch_count = self.samples // batch_size\n","        dlosses = []\n","        glosses = []\n","        for epo in range(1,epochs+1):\n","            print ('-'*15,'Epoch %d' % epo, '-'*15)\n","            for _ in tqdm(range(batch_count)):\n","\n","                # Training the Discriminator\n","\n","                # Generating Batch\n","                hr_imgs, real, lr_imgs, fake = next(pipeline)\n","\n","                # Generate high resolution photos from low resolution photos\n","                generated_hr_imags = self.generator.predict(lr_imgs)\n","\n","                # Train the discriminator \n","                real_dis_loss = self.discriminator.train_on_batch(hr_imgs,real)\n","                fake_dis_loss = self.discriminator.train_on_batch(generated_hr_imags,fake)\n","                dis_loss = (0.5*np.add(real_dis_loss,fake_dis_loss))\n","\n","                # Training the Generator\n","\n","                # Generating Batch\n","                hr_imgs, lr_imgs, real = next(vgg_pipeline)\n","\n","                # Extract ground truth using VGG model\n","                img_features = self.vgg.predict(hr_imgs)\n","\n","                gan_loss = self.srgan.train_on_batch([lr_imgs,hr_imgs], [real, img_features])\n","\n","\n","            if epo % save_interval == 0:\n","              self.save_GAN_Model(epo)\n","              self.plotLosses(dlosses,glosses,epo)\n","            dlosses.append(gan_loss[1])\n","            glosses.append(gan_loss[0])\n","            print('\\n',dlosses[-1],glosses[-1])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ldAY13zg97pD","colab":{}},"source":["def plot_predict(low_reso_imgs,high_reso_imgs,srgan_model,n_imgs = 4):\n","    plt.figure(figsize = (12,12))\n","    plt.tight_layout()\n","    for i in range(0,n_imgs*3,3):\n","        idx = np.random.randint(0,low_reso_imgs.shape[0]-1)\n","        plt.subplot(n_imgs,3,i+1)\n","        plt.imshow(high_reso_imgs[idx])\n","        plt.grid('off')\n","        plt.axis('off')\n","        plt.title('Source')\n","        plt.subplot(n_imgs,3,i+2)\n","        plt.imshow(cv2.resize(low_reso_imgs[idx],(256,256),\n","                          interpolation = cv2.INTER_CUBIC))\n","        plt.grid('off')\n","        plt.axis('off')\n","        plt.title('X4 (bicubic)')\n","        \n","        img = srgan_model.generator.predict(np.expand_dims(low_reso_imgs[idx], axis = 0) / 127.5 - 1)\n","        img_unnorm = (img+1) * 127.5\n","        plt.subplot(n_imgs,3,i+3)\n","        plt.imshow(np.squeeze(img_unnorm, axis = 0).astype(np.uint8))\n","        plt.grid('off')\n","        plt.axis('off')\n","        plt.title('SRGAN')\n","        \n","    plt.de('predicted.png')\n","        \n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oSbXQP-6pnB1","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":303},"outputId":"3d624991-8427-4ad0-8bb7-02d699ae855c","executionInfo":{"status":"error","timestamp":1575354642335,"user_tz":-330,"elapsed":15031,"user":{"displayName":"Noor Fatima","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mApQYMABtajgCZCy7cF1as2H2UpI9g5drQw9DFD=s64","userId":"06775967229168824100"}}},"source":["model_srgan = SRGAN()"],"execution_count":17,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-1b41366ffd02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_srgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSRGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-ab01ae424588>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lr_height, lr_width, channels, upscale_factor, generator_lr, discriminator_lr, gan_lr)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopti_discriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopti_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_srgan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopti_gan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-ab01ae424588>\u001b[0m in \u001b[0;36mbuild_generator\u001b[0;34m(self, opti_generator, n_blocks)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_blocks\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mresidual_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresidual_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         output_residual = Conv2D(filters = 96, kernel_size = 3,\n","\u001b[0;32m<ipython-input-15-ab01ae424588>\u001b[0m in \u001b[0;36mresidual_block\u001b[0;34m(self, input_layer)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# sample variance - unbiased estimator of population variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mvariance\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0msample_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         self.add_update([K.moving_average_update(self.moving_mean,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m           y = ops.convert_to_tensor_v2(\n\u001b[0;32m--> 903\u001b[0;31m               y, dtype_hint=x.dtype.base_dtype, name=\"y\")\n\u001b[0m\u001b[1;32m    904\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m           \u001b[0;31m# If the RHS is not a tensor, it might be a tensor aware object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1283\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         ret = conversion_func(\n\u001b[0;32m-> 1285\u001b[0;31m             value, dtype=preferred_dtype, name=name, as_ref=as_ref)\n\u001b[0m\u001b[1;32m   1286\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;31m# Could not coerce the conversion to use the preferred dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    269\u001b[0m       attrs={\"value\": tensor_value,\n\u001b[1;32m    270\u001b[0m              \"dtype\": dtype_value},\n\u001b[0;32m--> 271\u001b[0;31m       name=name).outputs[0]\n\u001b[0m\u001b[1;32m    272\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3355\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0;32m-> 3357\u001b[0;31m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[1;32m   3358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m   def _create_op_internal(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3409\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3411\u001b[0;31m     \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_NodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3413\u001b[0m     \u001b[0minput_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_NodeDef\u001b[0;34m(op_type, name, device, attrs)\u001b[0m\n\u001b[1;32m   1546\u001b[0m   \"\"\"\n\u001b[1;32m   1547\u001b[0m   \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_def_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1548\u001b[0;31m   \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1549\u001b[0m   \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"I0U6io4lCVWI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":624,"referenced_widgets":["3b3ec0eec9fd41ffa8ce56728a27087e","907926931ca545dfa8a0c21574675829","0db3b1e68df94c73a05152ed4e738f99","975bc316ef2e4c7d97153e4cd77df620","98fca5419dae4b2599414a8b58551a4c","a09511caf4f14e7da70d9c5fb37f8cb5","dd31fadd03714049b7b40b5ad87888d0","dedf9fb6d2e848edbdf19fe5032daa10"]},"outputId":"0b3db411-1e8d-4f1a-9aa3-95c917648bd9","executionInfo":{"status":"error","timestamp":1575354663771,"user_tz":-330,"elapsed":17652,"user":{"displayName":"Noor Fatima","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mApQYMABtajgCZCy7cF1as2H2UpI9g5drQw9DFD=s64","userId":"06775967229168824100"}}},"source":["model_srgan.train(500)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["--------------- Epoch 1 ---------------\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b3ec0eec9fd41ffa8ce56728a27087e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-02b63a388367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_srgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-c5f5aeca3f90>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, save_interval, batch_size)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mimg_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mgan_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlr_imgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhr_imgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[16,96,384,384] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_3/p_re_lu_19/add-1-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[loss_3/add/_2785]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[16,96,384,384] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_3/p_re_lu_19/add-1-TransposeNHWCToNCHW-LayoutOptimizer}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."]}]},{"cell_type":"code","metadata":{"id":"ZWhdSeU7avly","colab_type":"code","colab":{}},"source":["# model_srgan.compile"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eDxrE-4rYPaG","colab_type":"code","colab":{}},"source":["model_srgan.generator.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlFqsfzysHHK","colab_type":"code","colab":{}},"source":["model_srgan.discriminator.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KnWc5qfNqu2P","colab_type":"code","colab":{}},"source":["os.chdir('/content')\n","!mkdir training_process\n","os.chdir('./training_process')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TgvFu_CzCApH","colab_type":"code","colab":{}},"source":["ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8udzdh_v5Qk","colab_type":"code","colab":{}},"source":["shutil.move('/content/srgan_weights_epoch_1.h5', os.getcwd())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Onze8-CvW9j0","colab":{}},"source":["# model_srgan.srgan.load_weights('srgan_weights_epoch_1.h5')\n","model_srgan.train(500, save_interval=20 ,batch_size=16)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TtK2lGaQcZiI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2k3dhYEZlcHf","colab_type":"code","colab":{}},"source":["# Load pretrained model\n","model_srgan.srgan.load_weights('srgan_weights_epoch_450.h5')\n","plot_predict(low_reso_imgs,high_reso_imgs,model_srgan)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtICrmZDGd9A","colab_type":"code","colab":{}},"source":["#plt.imshow(testimg)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EPpgU1-6Gf5f","colab_type":"code","colab":{}},"source":["def predict_on_test(image):\n","  plt.figure(figsize = (12,12))\n","  plt.tight_layout()\n","    \n","  # idx = np.random.randint(0, images.shape[0]-1)\n","  # plt.subplot(n_imgs,3,i+1)\n","  # plt.imshow(high_reso_imgs[idx])\n","  plt.grid('off')\n","  plt.axis('off')\n","  plt.title('Source')\n","  # plt.subplot(n_imgs,3,i+2)\n","\n","  plt.imshow(cv2.resize(image,(64,64),\n","                    interpolation = cv2.INTER_CUBIC))\n","  plt.grid('off')\n","  plt.axis('off')\n","  plt.title('X4 (bicubic)')\n","  \n","  img = model_srgan.generator.predict(np.expand_dims(image, axis = 0) / 127.5 - 1)\n","  img_unnorm = (img+1) * 127.5\n","  plt.subplot(n_imgs,3,i+3)\n","  plt.imshow(np.squeeze(img_unnorm, axis = 0).astype(np.uint8))\n","  plt.grid('off')\n","  plt.axis('off')\n","  plt.title('SRGAN')\n","        \n","  plt.de('predicted.png')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TcHz8glaH8_Q","colab_type":"code","colab":{}},"source":["def preprocess(path):\n","  img = cv2.imread(path)\n","  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","  img_crop = crop_center(img,256,256)\n","  return cv2.resize(img_crop, (64, 64))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9kNuL8pIxOE","colab_type":"code","colab":{}},"source":["path = '/content/train_data/DIV2K_train_HR/0002.png'\n","plt.imshow(preprocess(path))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FUMmzRUGI38R","colab_type":"code","colab":{}},"source":["def infer(path):\n","  image = preprocess(path)\n","  print(image.shape)\n","  img = model_srgan.generator.predict(np.expand_dims(image, axis = 0) / 127.5 - 1)\n","  plt.imshow(np.squeeze(img))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S89--trjJSj2","colab_type":"code","colab":{}},"source":["infer(path)"],"execution_count":0,"outputs":[]}]}